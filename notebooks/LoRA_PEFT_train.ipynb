{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "101443bd",
   "metadata": {},
   "source": [
    "## LoRA + PEFT Fine-Tuning of Stable Diffusion with Metric Logging\n",
    "\n",
    "This notebook fine-tunes the Stable Diffusion v1.5 model using Low-Rank\n",
    "Adaptation (LoRA) and the PEFT framework on a custom speed-bump image–caption\n",
    "dataset. The base model weights are frozen, and only LoRA adapter parameters\n",
    "are trained. Training loss is logged at each step and saved as a JSON file for\n",
    "visualization and analysis. The trained LoRA adapters are saved for\n",
    "downstream testing and CLIP-based evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b7e9ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "from diffusers import StableDiffusionPipeline\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791b6f19",
   "metadata": {},
   "source": [
    "#### Path setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76aefa9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset directory: D:\\work_space\\projects\\deep_learning\\CAP6415_F25_project-Finding-and-solving-hard-to-generate-examples\\data\\processed\\lora_ready\n",
      "Output directory: D:\\work_space\\projects\\deep_learning\\CAP6415_F25_project-Finding-and-solving-hard-to-generate-examples\\model\\lora_peft_checkpoint\n"
     ]
    }
   ],
   "source": [
    "# PATH CONFIGURATION\n",
    "IMG_DIR = Path(r\"D:\\work_space\\projects\\deep_learning\\CAP6415_F25_project-Finding-and-solving-hard-to-generate-examples\\data\\processed\\lora_ready\")\n",
    "\n",
    "OUTPUT_DIR = Path(r\"D:\\work_space\\projects\\deep_learning\\CAP6415_F25_project-Finding-and-solving-hard-to-generate-examples\\model\\lora_peft_checkpoint\")\n",
    "\n",
    "METRICS_DIR = Path(r\"D:\\work_space\\projects\\deep_learning\\CAP6415_F25_project-Finding-and-solving-hard-to-generate-examples\\results\\Metrics_json\")\n",
    "\n",
    "METRICS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if not IMG_DIR.exists():\n",
    "    raise RuntimeError(f\"Dataset directory not found: {IMG_DIR}\")\n",
    "\n",
    "print(\"Dataset directory:\", IMG_DIR)\n",
    "print(\"Output directory:\", OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6d7281",
   "metadata": {},
   "source": [
    "#### Training configurations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a964b4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING CONFIG\n",
    "@dataclass\n",
    "class TrainConfig:\n",
    "    model_id: str = \"runwayml/stable-diffusion-v1-5\"\n",
    "    resolution: int = 512\n",
    "    train_batch_size: int = 1\n",
    "    gradient_accumulation_steps: int = 4\n",
    "    learning_rate: float = 1e-4\n",
    "    max_train_steps: int = 1500 # keep this small for debug\n",
    "    mixed_precision: str = \"fp16\" # fp16 for RTX 3050\n",
    "    rank: int = 4\n",
    "    seed: int = 42\n",
    "\n",
    "cfg = TrainConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "689cf4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMALL UTIL FUNCTIONS\n",
    "def log(msg):\n",
    "    print(f\"[{datetime.now().strftime('%H:%M:%S')}] {msg}\")\n",
    "\n",
    "def set_seed(seed):\n",
    "    \"\"\"For reproducibility. so basically to control the sequence of the random numbers\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3421f94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASET\n",
    "class LoraDebugDataset(Dataset):\n",
    "    \"\"\"It load the data from folder and resizes and normalizes the images and returns the image+caption formate to train the lora\"\"\"\n",
    "    def __init__(self, img_dir: Path, resolution: int):\n",
    "        self.img_dir = img_dir\n",
    "        self.image_files = [\n",
    "            f for f in img_dir.iterdir()\n",
    "            if f.suffix.lower() in [\".jpg\", \".jpeg\", \".png\", \".bmp\"]\n",
    "        ]\n",
    "\n",
    "        if len(self.image_files) == 0:\n",
    "            raise RuntimeError(\"No images found in dataset folder!\")\n",
    "\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((resolution, resolution)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.5], [0.5])\n",
    "        ])\n",
    "\n",
    "        log(f\"Dataset loaded with {len(self.image_files)} images\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        txt_path = img_path.with_suffix(\".txt\")\n",
    "\n",
    "        caption = txt_path.read_text(encoding=\"utf-8\").strip()\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        image = self.transform(image)\n",
    "\n",
    "        return {\n",
    "            \"pixel_values\": image,\n",
    "            \"caption\": caption\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ea0b11",
   "metadata": {},
   "source": [
    "#### Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2586f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN TRAINING FUNCTION\n",
    "def main():\n",
    "\n",
    "    # BASIC SETUP \n",
    "    set_seed(cfg.seed)\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    log(f\"Using device: {device}\")\n",
    "\n",
    "    # LOAD MODEL \n",
    "    log(\"Loading Stable Diffusion base model...\")\n",
    "    pipe = StableDiffusionPipeline.from_pretrained(\n",
    "        cfg.model_id,\n",
    "        torch_dtype=torch.float16 if cfg.mixed_precision == \"fp16\" else torch.float32,\n",
    "        safety_checker=None\n",
    "    ).to(device)\n",
    "\n",
    "    tokenizer = pipe.tokenizer\n",
    "    text_encoder = pipe.text_encoder\n",
    "    vae = pipe.vae\n",
    "    unet = pipe.unet\n",
    "    scheduler = pipe.scheduler\n",
    "\n",
    "    # FREEZE BASE MODEL \n",
    "    print(\"\\n\")\n",
    "    log(\"Freezing VAE and Text Encoder...\")\n",
    "    vae.requires_grad_(False)\n",
    "    text_encoder.requires_grad_(False)\n",
    "    unet.requires_grad_(False)\n",
    "\n",
    "    if hasattr(unet, \"enable_gradient_checkpointing\"):\n",
    "        unet.enable_gradient_checkpointing()\n",
    "\n",
    "    # ADD LORA \n",
    "    log(\"Injecting LoRA into UNet...\")\n",
    "    lora_config = LoraConfig(\n",
    "        r=cfg.rank,\n",
    "        lora_alpha=cfg.rank * 4,\n",
    "        lora_dropout=0.1,\n",
    "        target_modules=[\"to_q\", \"to_k\", \"to_v\", \"to_out.0\"]\n",
    "    )\n",
    "\n",
    "    unet = get_peft_model(unet, lora_config).to(device)\n",
    "    unet.train()\n",
    "\n",
    "    trainable_params = [p for p in unet.parameters() if p.requires_grad]\n",
    "    log(f\"Trainable LoRA parameters: {sum(p.numel() for p in trainable_params):,}\")\n",
    "\n",
    "    # DATASET & DATALOADER \n",
    "    dataset = LoraDebugDataset(IMG_DIR, cfg.resolution)\n",
    "\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=cfg.train_batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=0,\n",
    "        pin_memory=(device == \"cuda\")\n",
    "    )\n",
    "\n",
    "    # OPTIMIZER & AMP \n",
    "    optimizer = torch.optim.AdamW(trainable_params, lr=cfg.learning_rate)\n",
    "    use_fp16 = cfg.mixed_precision == \"fp16\" and device == \"cuda\"\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=use_fp16)\n",
    "\n",
    "    # METRIC LOGGING \n",
    "    train_losses = []\n",
    "    step_history = []\n",
    "\n",
    "    # TRAINING LOOP \n",
    "    global_step = 0\n",
    "    print(\"\\n\")\n",
    "    log(\"START TRAINING\")\n",
    "\n",
    "    while global_step < cfg.max_train_steps:\n",
    "        for batch_idx, batch in enumerate(dataloader):\n",
    "\n",
    "            if global_step >= cfg.max_train_steps:\n",
    "                break\n",
    "\n",
    "            with torch.cuda.amp.autocast(enabled=use_fp16):\n",
    "\n",
    "                # TEXT -> EMBEDDINGS\n",
    "                captions = batch[\"caption\"]\n",
    "                encoding = tokenizer(\n",
    "                    list(captions),\n",
    "                    padding=\"max_length\",\n",
    "                    truncation=True,\n",
    "                    max_length=tokenizer.model_max_length,\n",
    "                    return_tensors=\"pt\"\n",
    "                ).to(device)\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    text_embeddings = text_encoder(encoding.input_ids)[0]\n",
    "\n",
    "                # IMAGE -> LATENTS\n",
    "                pixels = batch[\"pixel_values\"].to(device)\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    latents = vae.encode(pixels).latent_dist.sample()\n",
    "                    latents = latents * 0.18215\n",
    "\n",
    "                # NOISE & TIMESTEP\n",
    "                noise = torch.randn_like(latents)\n",
    "                t = torch.randint(\n",
    "                    0,\n",
    "                    scheduler.config.num_train_timesteps,\n",
    "                    (latents.shape[0],),\n",
    "                    device=device\n",
    "                )\n",
    "\n",
    "                noisy_latents = scheduler.add_noise(latents, noise, t)\n",
    "\n",
    "                # UNET PREDICTION\n",
    "                preds = unet(\n",
    "                    noisy_latents,\n",
    "                    t,\n",
    "                    encoder_hidden_states=text_embeddings\n",
    "                ).sample\n",
    "\n",
    "                # LOSS\n",
    "                loss = nn.functional.mse_loss(preds, noise)\n",
    "                loss = loss / cfg.gradient_accumulation_steps\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "\n",
    "            if (global_step + 1) % cfg.gradient_accumulation_steps == 0:\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "            # LOG METRICS\n",
    "            train_losses.append(loss.item() * cfg.gradient_accumulation_steps)\n",
    "            step_history.append(global_step)\n",
    "\n",
    "            if global_step % 10 == 0:\n",
    "                gpu_mem = (\n",
    "                    torch.cuda.memory_allocated() / (1024 ** 3)\n",
    "                    if device == \"cuda\" else 0\n",
    "                )\n",
    "\n",
    "                log(\n",
    "                    f\"Step {global_step:04d} | \"\n",
    "                    f\"Loss: {loss.item() * cfg.gradient_accumulation_steps:.6f} | \"\n",
    "                    f\"GPU Mem: {gpu_mem:.2f} GB\"\n",
    "                )\n",
    "\n",
    "            global_step += 1\n",
    "\n",
    "    # SAVE LOGS \n",
    "    log_data = {\n",
    "        \"steps\": step_history,\n",
    "        \"train_loss\": train_losses\n",
    "    }\n",
    "\n",
    "    with open(METRICS_DIR / \"train_logs.json\", \"w\") as f:\n",
    "        json.dump(log_data, f)\n",
    "        \n",
    "    print(\"\\n\")\n",
    "    log(\"Training logs saved.\")\n",
    "\n",
    "    # SAVE TRAINED LORA \n",
    "    log(\"Saving trained LoRA adapter...\")\n",
    "    unet.save_pretrained(OUTPUT_DIR)\n",
    "\n",
    "    log(\"TRAINING COMPLETE\")\n",
    "    log(f\"LoRA saved to: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "043e6651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:44:25] Using device: cuda\n",
      "[23:44:25] Loading Stable Diffusion base model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 6/6 [00:07<00:00,  1.23s/it]\n",
      "You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[23:44:34] Freezing VAE and Text Encoder...\n",
      "[23:44:34] Injecting LoRA into UNet...\n",
      "[23:44:35] Trainable LoRA parameters: 797,184\n",
      "[23:44:35] Dataset loaded with 61 images\n",
      "\n",
      "\n",
      "[23:44:35] START TRAINING\n",
      "[23:44:38] Step 0000 | Loss: 0.666697 | GPU Mem: 2.05 GB\n",
      "[23:44:46] Step 0010 | Loss: 0.131168 | GPU Mem: 2.05 GB\n",
      "[23:44:54] Step 0020 | Loss: 0.096082 | GPU Mem: 2.05 GB\n",
      "[23:45:02] Step 0030 | Loss: 0.009931 | GPU Mem: 2.05 GB\n",
      "[23:45:11] Step 0040 | Loss: 0.054086 | GPU Mem: 2.05 GB\n",
      "[23:45:19] Step 0050 | Loss: 0.144473 | GPU Mem: 2.05 GB\n",
      "[23:45:27] Step 0060 | Loss: 0.016732 | GPU Mem: 2.05 GB\n",
      "[23:45:35] Step 0070 | Loss: 0.398107 | GPU Mem: 2.05 GB\n",
      "[23:45:42] Step 0080 | Loss: 0.070085 | GPU Mem: 2.05 GB\n",
      "[23:45:50] Step 0090 | Loss: 0.023817 | GPU Mem: 2.05 GB\n",
      "[23:45:59] Step 0100 | Loss: 0.052459 | GPU Mem: 2.05 GB\n",
      "[23:46:07] Step 0110 | Loss: 0.003549 | GPU Mem: 2.05 GB\n",
      "[23:46:15] Step 0120 | Loss: 0.069916 | GPU Mem: 2.05 GB\n",
      "[23:46:23] Step 0130 | Loss: 0.064113 | GPU Mem: 2.05 GB\n",
      "[23:46:30] Step 0140 | Loss: 0.158782 | GPU Mem: 2.05 GB\n",
      "[23:46:39] Step 0150 | Loss: 0.012502 | GPU Mem: 2.05 GB\n",
      "[23:46:46] Step 0160 | Loss: 0.004634 | GPU Mem: 2.05 GB\n",
      "[23:46:54] Step 0170 | Loss: 0.004113 | GPU Mem: 2.05 GB\n",
      "[23:47:02] Step 0180 | Loss: 0.028361 | GPU Mem: 2.05 GB\n",
      "[23:47:10] Step 0190 | Loss: 0.308496 | GPU Mem: 2.05 GB\n",
      "[23:47:18] Step 0200 | Loss: 0.033946 | GPU Mem: 2.05 GB\n",
      "[23:47:26] Step 0210 | Loss: 0.004869 | GPU Mem: 2.05 GB\n",
      "[23:47:34] Step 0220 | Loss: 0.010934 | GPU Mem: 2.05 GB\n",
      "[23:47:41] Step 0230 | Loss: 0.473721 | GPU Mem: 2.05 GB\n",
      "[23:47:49] Step 0240 | Loss: 0.021487 | GPU Mem: 2.05 GB\n",
      "[23:47:57] Step 0250 | Loss: 0.060056 | GPU Mem: 2.05 GB\n",
      "[23:48:05] Step 0260 | Loss: 0.006897 | GPU Mem: 2.05 GB\n",
      "[23:48:13] Step 0270 | Loss: 0.072654 | GPU Mem: 2.05 GB\n",
      "[23:48:20] Step 0280 | Loss: 0.136270 | GPU Mem: 2.05 GB\n",
      "[23:48:28] Step 0290 | Loss: 0.033115 | GPU Mem: 2.05 GB\n",
      "[23:48:36] Step 0300 | Loss: 0.039171 | GPU Mem: 2.05 GB\n",
      "[23:48:44] Step 0310 | Loss: 0.243259 | GPU Mem: 2.05 GB\n",
      "[23:48:52] Step 0320 | Loss: 0.019619 | GPU Mem: 2.05 GB\n",
      "[23:48:59] Step 0330 | Loss: 0.010363 | GPU Mem: 2.05 GB\n",
      "[23:49:07] Step 0340 | Loss: 0.003610 | GPU Mem: 2.05 GB\n",
      "[23:49:15] Step 0350 | Loss: 0.162381 | GPU Mem: 2.05 GB\n",
      "[23:49:23] Step 0360 | Loss: 0.005666 | GPU Mem: 2.05 GB\n",
      "[23:49:31] Step 0370 | Loss: 0.278371 | GPU Mem: 2.05 GB\n",
      "[23:49:39] Step 0380 | Loss: 0.028379 | GPU Mem: 2.05 GB\n",
      "[23:49:46] Step 0390 | Loss: 0.065537 | GPU Mem: 2.05 GB\n",
      "[23:49:54] Step 0400 | Loss: 0.832698 | GPU Mem: 2.05 GB\n",
      "[23:50:02] Step 0410 | Loss: 0.004294 | GPU Mem: 2.05 GB\n",
      "[23:50:10] Step 0420 | Loss: 0.271326 | GPU Mem: 2.05 GB\n",
      "[23:50:17] Step 0430 | Loss: 0.045806 | GPU Mem: 2.05 GB\n",
      "[23:50:25] Step 0440 | Loss: 0.009238 | GPU Mem: 2.05 GB\n",
      "[23:50:33] Step 0450 | Loss: 0.011365 | GPU Mem: 2.05 GB\n",
      "[23:50:41] Step 0460 | Loss: 0.010616 | GPU Mem: 2.05 GB\n",
      "[23:50:49] Step 0470 | Loss: 0.251598 | GPU Mem: 2.05 GB\n",
      "[23:50:56] Step 0480 | Loss: 0.064890 | GPU Mem: 2.05 GB\n",
      "[23:51:04] Step 0490 | Loss: 0.004135 | GPU Mem: 2.05 GB\n",
      "[23:51:12] Step 0500 | Loss: 0.008674 | GPU Mem: 2.05 GB\n",
      "[23:51:20] Step 0510 | Loss: 0.322519 | GPU Mem: 2.05 GB\n",
      "[23:51:28] Step 0520 | Loss: 0.120900 | GPU Mem: 2.05 GB\n",
      "[23:51:35] Step 0530 | Loss: 0.003952 | GPU Mem: 2.05 GB\n",
      "[23:51:43] Step 0540 | Loss: 0.039684 | GPU Mem: 2.05 GB\n",
      "[23:51:51] Step 0550 | Loss: 0.172408 | GPU Mem: 2.05 GB\n",
      "[23:51:59] Step 0560 | Loss: 0.162226 | GPU Mem: 2.05 GB\n",
      "[23:52:07] Step 0570 | Loss: 0.070356 | GPU Mem: 2.05 GB\n",
      "[23:52:14] Step 0580 | Loss: 0.060823 | GPU Mem: 2.05 GB\n",
      "[23:52:22] Step 0590 | Loss: 0.925238 | GPU Mem: 2.05 GB\n",
      "[23:52:30] Step 0600 | Loss: 0.078654 | GPU Mem: 2.05 GB\n",
      "[23:52:38] Step 0610 | Loss: 0.087220 | GPU Mem: 2.05 GB\n",
      "[23:52:46] Step 0620 | Loss: 0.086293 | GPU Mem: 2.05 GB\n",
      "[23:52:53] Step 0630 | Loss: 0.119450 | GPU Mem: 2.05 GB\n",
      "[23:53:01] Step 0640 | Loss: 0.013257 | GPU Mem: 2.05 GB\n",
      "[23:53:09] Step 0650 | Loss: 0.039766 | GPU Mem: 2.05 GB\n",
      "[23:53:17] Step 0660 | Loss: 0.208958 | GPU Mem: 2.05 GB\n",
      "[23:53:25] Step 0670 | Loss: 0.003564 | GPU Mem: 2.05 GB\n",
      "[23:53:32] Step 0680 | Loss: 0.107609 | GPU Mem: 2.05 GB\n",
      "[23:53:40] Step 0690 | Loss: 0.311832 | GPU Mem: 2.05 GB\n",
      "[23:53:48] Step 0700 | Loss: 0.010223 | GPU Mem: 2.05 GB\n",
      "[23:53:56] Step 0710 | Loss: 0.210140 | GPU Mem: 2.05 GB\n",
      "[23:54:03] Step 0720 | Loss: 0.472039 | GPU Mem: 2.05 GB\n",
      "[23:54:11] Step 0730 | Loss: 0.085056 | GPU Mem: 2.05 GB\n",
      "[23:54:19] Step 0740 | Loss: 0.017611 | GPU Mem: 2.05 GB\n",
      "[23:54:27] Step 0750 | Loss: 0.072115 | GPU Mem: 2.05 GB\n",
      "[23:54:34] Step 0760 | Loss: 0.284319 | GPU Mem: 2.05 GB\n",
      "[23:54:42] Step 0770 | Loss: 0.119790 | GPU Mem: 2.05 GB\n",
      "[23:54:50] Step 0780 | Loss: 0.029205 | GPU Mem: 2.05 GB\n",
      "[23:54:58] Step 0790 | Loss: 0.009013 | GPU Mem: 2.05 GB\n",
      "[23:55:06] Step 0800 | Loss: 0.027461 | GPU Mem: 2.05 GB\n",
      "[23:55:13] Step 0810 | Loss: 0.213552 | GPU Mem: 2.05 GB\n",
      "[23:55:21] Step 0820 | Loss: 0.139403 | GPU Mem: 2.05 GB\n",
      "[23:55:29] Step 0830 | Loss: 0.095240 | GPU Mem: 2.05 GB\n",
      "[23:55:37] Step 0840 | Loss: 0.141999 | GPU Mem: 2.05 GB\n",
      "[23:55:44] Step 0850 | Loss: 0.056333 | GPU Mem: 2.05 GB\n",
      "[23:55:52] Step 0860 | Loss: 0.110947 | GPU Mem: 2.05 GB\n",
      "[23:56:00] Step 0870 | Loss: 0.212179 | GPU Mem: 2.05 GB\n",
      "[23:56:08] Step 0880 | Loss: 0.025922 | GPU Mem: 2.05 GB\n",
      "[23:56:16] Step 0890 | Loss: 0.054422 | GPU Mem: 2.05 GB\n",
      "[23:56:23] Step 0900 | Loss: 0.053057 | GPU Mem: 2.05 GB\n",
      "[23:56:31] Step 0910 | Loss: 0.196797 | GPU Mem: 2.05 GB\n",
      "[23:56:39] Step 0920 | Loss: 0.077195 | GPU Mem: 2.05 GB\n",
      "[23:56:47] Step 0930 | Loss: 0.245542 | GPU Mem: 2.05 GB\n",
      "[23:56:54] Step 0940 | Loss: 0.233574 | GPU Mem: 2.05 GB\n",
      "[23:57:02] Step 0950 | Loss: 0.332228 | GPU Mem: 2.05 GB\n",
      "[23:57:10] Step 0960 | Loss: 0.058473 | GPU Mem: 2.05 GB\n",
      "[23:57:17] Step 0970 | Loss: 0.169147 | GPU Mem: 2.05 GB\n",
      "[23:57:25] Step 0980 | Loss: 0.443910 | GPU Mem: 2.05 GB\n",
      "[23:57:33] Step 0990 | Loss: 0.030835 | GPU Mem: 2.05 GB\n",
      "[23:57:41] Step 1000 | Loss: 0.254717 | GPU Mem: 2.05 GB\n",
      "[23:57:48] Step 1010 | Loss: 0.089094 | GPU Mem: 2.05 GB\n",
      "[23:57:56] Step 1020 | Loss: 0.141199 | GPU Mem: 2.05 GB\n",
      "[23:58:04] Step 1030 | Loss: 0.064801 | GPU Mem: 2.05 GB\n",
      "[23:58:12] Step 1040 | Loss: 0.091317 | GPU Mem: 2.05 GB\n",
      "[23:58:19] Step 1050 | Loss: 0.109637 | GPU Mem: 2.05 GB\n",
      "[23:58:27] Step 1060 | Loss: 0.275038 | GPU Mem: 2.05 GB\n",
      "[23:58:35] Step 1070 | Loss: 0.002059 | GPU Mem: 2.05 GB\n",
      "[23:58:42] Step 1080 | Loss: 0.052677 | GPU Mem: 2.05 GB\n",
      "[23:58:50] Step 1090 | Loss: 0.073713 | GPU Mem: 2.05 GB\n",
      "[23:58:58] Step 1100 | Loss: 0.068277 | GPU Mem: 2.05 GB\n",
      "[23:59:06] Step 1110 | Loss: 0.320394 | GPU Mem: 2.05 GB\n",
      "[23:59:13] Step 1120 | Loss: 0.045522 | GPU Mem: 2.05 GB\n",
      "[23:59:21] Step 1130 | Loss: 0.049727 | GPU Mem: 2.05 GB\n",
      "[23:59:29] Step 1140 | Loss: 0.076534 | GPU Mem: 2.05 GB\n",
      "[23:59:36] Step 1150 | Loss: 0.516709 | GPU Mem: 2.05 GB\n",
      "[23:59:44] Step 1160 | Loss: 0.029398 | GPU Mem: 2.05 GB\n",
      "[23:59:52] Step 1170 | Loss: 0.385015 | GPU Mem: 2.05 GB\n",
      "[00:00:00] Step 1180 | Loss: 0.003865 | GPU Mem: 2.05 GB\n",
      "[00:00:07] Step 1190 | Loss: 0.190024 | GPU Mem: 2.05 GB\n",
      "[00:00:15] Step 1200 | Loss: 0.258358 | GPU Mem: 2.05 GB\n",
      "[00:00:23] Step 1210 | Loss: 0.008758 | GPU Mem: 2.05 GB\n",
      "[00:00:30] Step 1220 | Loss: 0.014220 | GPU Mem: 2.05 GB\n",
      "[00:00:38] Step 1230 | Loss: 0.150519 | GPU Mem: 2.05 GB\n",
      "[00:00:46] Step 1240 | Loss: 0.114233 | GPU Mem: 2.05 GB\n",
      "[00:00:53] Step 1250 | Loss: 0.038298 | GPU Mem: 2.05 GB\n",
      "[00:01:01] Step 1260 | Loss: 0.178391 | GPU Mem: 2.05 GB\n",
      "[00:01:09] Step 1270 | Loss: 0.473624 | GPU Mem: 2.05 GB\n",
      "[00:01:16] Step 1280 | Loss: 0.093246 | GPU Mem: 2.05 GB\n",
      "[00:01:24] Step 1290 | Loss: 0.052955 | GPU Mem: 2.05 GB\n",
      "[00:01:32] Step 1300 | Loss: 0.098016 | GPU Mem: 2.05 GB\n",
      "[00:01:40] Step 1310 | Loss: 0.030186 | GPU Mem: 2.05 GB\n",
      "[00:01:47] Step 1320 | Loss: 0.223094 | GPU Mem: 2.05 GB\n",
      "[00:01:55] Step 1330 | Loss: 0.053395 | GPU Mem: 2.05 GB\n",
      "[00:02:03] Step 1340 | Loss: 0.038183 | GPU Mem: 2.05 GB\n",
      "[00:02:10] Step 1350 | Loss: 0.013502 | GPU Mem: 2.05 GB\n",
      "[00:02:18] Step 1360 | Loss: 0.175992 | GPU Mem: 2.05 GB\n",
      "[00:02:26] Step 1370 | Loss: 0.003712 | GPU Mem: 2.05 GB\n",
      "[00:02:34] Step 1380 | Loss: 0.281007 | GPU Mem: 2.05 GB\n",
      "[00:02:41] Step 1390 | Loss: 0.008520 | GPU Mem: 2.05 GB\n",
      "[00:02:49] Step 1400 | Loss: 0.003617 | GPU Mem: 2.05 GB\n",
      "[00:02:57] Step 1410 | Loss: 0.027205 | GPU Mem: 2.05 GB\n",
      "[00:03:04] Step 1420 | Loss: 0.204100 | GPU Mem: 2.05 GB\n",
      "[00:03:12] Step 1430 | Loss: 0.018047 | GPU Mem: 2.05 GB\n",
      "[00:03:20] Step 1440 | Loss: 0.041988 | GPU Mem: 2.05 GB\n",
      "[00:03:28] Step 1450 | Loss: 0.017198 | GPU Mem: 2.05 GB\n",
      "[00:03:36] Step 1460 | Loss: 0.025523 | GPU Mem: 2.05 GB\n",
      "[00:03:44] Step 1470 | Loss: 0.009580 | GPU Mem: 2.05 GB\n",
      "[00:03:51] Step 1480 | Loss: 0.181014 | GPU Mem: 2.05 GB\n",
      "[00:03:59] Step 1490 | Loss: 0.254742 | GPU Mem: 2.05 GB\n",
      "\n",
      "\n",
      "[00:04:06] Training logs saved.\n",
      "[00:04:06] Saving trained LoRA adapter...\n",
      "[00:04:06] TRAINING COMPLETE\n",
      "[00:04:06] LoRA saved to: D:\\work_space\\projects\\deep_learning\\CAP6415_F25_project-Finding-and-solving-hard-to-generate-examples\\model\\lora_peft_checkpoint\n"
     ]
    }
   ],
   "source": [
    "# RUN\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b14880",
   "metadata": {},
   "source": [
    "### Code Explanation \n",
    "\n",
    "This script sets up and executes LoRA-based fine-tuning of Stable Diffusion on a\n",
    "custom image–caption dataset. After loading required libraries and defining\n",
    "directory paths, a training configuration dataclass is used to store all\n",
    "hyperparameters in a clean and reproducible format.\n",
    "\n",
    "A custom PyTorch dataset class loads the LoRA-ready images and their matching\n",
    "caption files, resizes them to 512×512, converts them to tensors, and applies\n",
    "normalization suitable for Stable Diffusion.\n",
    "\n",
    "Inside the main training function, the Stable Diffusion base model is loaded\n",
    "and its VAE, text encoder, and UNet parameters are frozen. LoRA adapters are\n",
    "then injected into the UNet attention layers using PEFT, making only the LoRA\n",
    "parameters trainable.\n",
    "\n",
    "During each training step, captions are tokenized and encoded into text\n",
    "embeddings, images are converted into latent representations using the VAE,\n",
    "and Gaussian noise is added according to the diffusion scheduler. The UNet is\n",
    "trained to predict this noise using a Mean Squared Error (MSE) loss function.\n",
    "Gradient accumulation and mixed-precision training are used for efficient GPU\n",
    "utilization.\n",
    "\n",
    "Training loss and step numbers are logged and saved as a JSON file for later\n",
    "visualization. After training completes, the learned LoRA adapter weights are\n",
    "saved to disk for inference and evaluation.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lock_in",
   "language": "python",
   "name": "lockin"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
