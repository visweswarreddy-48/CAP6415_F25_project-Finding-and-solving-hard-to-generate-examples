# CAP6415_F25_project-Finding-and-solving-hard-to-generate-examples

---

## ğŸ§  Project Overview

Modern text-to-image diffusion models such as **Stable Diffusion** can generate stunning visuals but still struggle with certain rare or visually ambiguous objects.  
One such object is the **speed bump**, which appears in many shapes, colours, and lighting conditions yet is under-represented in most large-scale datasets.

This project explores how to:
1. Identify such **hard-to-generate objects**.
2. Evaluate how poorly they are represented by pretrained diffusion models.
3. Improve the modelâ€™s performance through **fine-tuning** (e.g. LoRA or Textual Inversion).
4. Quantitatively and qualitatively evaluate improvements.

The project focuses on **â€œspeed bumpâ€** as a case study and aims to generate more accurate and realistic images through targeted data augmentation and model adaptation.

---

## ğŸ¯ Objectives
- âœ… Test baseline Stable Diffusion performance on â€œspeed bumpâ€ prompts.
- âœ… Collect a small dataset of real-world speed-bump images.
- âœ… Apply lightweight fine-tuning using LoRA or Textual Inversion.
- âœ… Evaluate improvement with CLIP similarity, FID, and visual inspection.

---

## ğŸ§© Framework and Tools
- **Language:** Python 3.10  
- **Core Libraries:** PyTorch, Hugging Face Diffusers, Transformers  
- **Fine-tuning:** LoRA / Textual Inversion (planned)  
- **Evaluation:** CLIP similarity, FID  
- **System Requirements:**  
  - Windows 10 / 11 or Linux  
  - GPU with â‰¥6 GB VRAM (recommended: NVIDIA RTX 3060 or better)  
  - CUDA 12.1 or higher  

---

## ğŸ“‚ Repository Structure

CAP6415_F25_project-Speed-Bump-Generation/
â”‚
â”œâ”€â”€ README.md # Project overview and setup guide
â”œâ”€â”€ requirements.txt # Required dependencies
â”œâ”€â”€ weekly_logs
â”‚ â””â”€â”€ week1log.txt # Week 1 activity log
â”œâ”€â”€ notebooks/
â”‚ â””â”€â”€ baseline_generation.ipynb # Baseline Stable Diffusion test
â”‚
â”œâ”€â”€ src/ # Source scripts (to be added)
â”‚
â””â”€â”€ results/
â””â”€â”€ baseline_speedbump.png


---

## âš™ï¸ Environment Setup and Installation

### Step 1ï¸âƒ£ â€” Clone this repository
Open your terminal or PowerShell and run:
```bash
git clone https://github.com/YOUR_USERNAME/CAP6415_F25_project-Speed-Bump-Generation.git
cd CAP6415_F25_project-Speed-Bump-Generation

```
### Step 2ï¸âƒ£ â€” Create and activate a virtual environment

Windows (PowerShell or CMD):
```bash
python -m venv deep_learning_env
deep_learning_env\Scripts\activate
``` 
macOS / Linux:
```bash
python3 -m venv deep_learning_env
source deep_learning_env/bin/activate

```
### Step 3ï¸âƒ£ Install dependencies
```bash
pip install --upgrade pip
pip install -r requirements.txt
